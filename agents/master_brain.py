"""
Master Brain v2.0 - Universal Intelligence Layer
=================================================
This is the REAL AI that THINKS like ChatGPT.

Architecture:
1. Gemini 2.0 Flash - Fast reasoning and internet search
2. Physics Engine - Hard constraints for calculable things (EV â†’ AQI)
3. Research Module - Internet search for any topic
4. Response Generator - Natural, conversational responses

What it handles:
- Urban planning queries (traffic, AQI, infrastructure)
- Hypothetical scenarios ("What if Noida bans cars?")
- General questions (anything about cities, mobility, policy)
- Real-time data lookup when needed

Key insight: The ML models we had before were NOT AI - they were regression models.
THIS is the actual AI - Gemini reasoning + physics validation.
"""

import os
import json
import re
import asyncio
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
import pandas as pd
import numpy as np
from pathlib import Path

# Gemini for reasoning
try:
    import google.generativeai as genai
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if GEMINI_API_KEY:
        genai.configure(api_key=GEMINI_API_KEY)
        GEMINI_AVAILABLE = True
    else:
        print("[MasterBrain] âš  GEMINI_API_KEY not set - using fallback responses")
        GEMINI_AVAILABLE = False
except ImportError:
    GEMINI_AVAILABLE = False


class MasterBrain:
    """
    The Universal Brain - handles ANY query intelligently.
    
    Three modes:
    1. CALCULABLE: EV adoption, signal optimization â†’ Use physics formulas
    2. RESEARCHABLE: Policy questions, comparisons â†’ Use Gemini + internet
    3. HYPOTHETICAL: "What if" scenarios â†’ Combine both + creativity
    
    Always transparent about:
    - What's calculated vs reasoned
    - Confidence levels
    - Data sources
    """
    
    def __init__(self):
        if GEMINI_AVAILABLE:
            # Use gemini-2.0-flash for speed
            self.model = genai.GenerativeModel('gemini-2.0-flash')
            # Also create a more powerful model for complex research
            self.research_model = genai.GenerativeModel('gemini-2.0-flash')
        else:
            self.model = None
            self.research_model = None
        
        # Load real Noida data
        self.traffic_data = None
        self.aqi_data = None
        self._load_data()
        
        # Noida baselines (from real data)
        self.baselines = self._calculate_baselines()
        
        # Physical constants for CALCULABLE scenarios
        self.physics = {
            # EV Impact on AQI (CANNOT be violated)
            "ev_aqi_reduction_per_percent": 0.0025,  # 0.25% AQI reduction per 1% EV
            "max_ev_aqi_reduction": 0.35,  # Max 35% reduction at 100% EV
            
            # Traffic interventions
            "ev_traffic_impact": 0.0,  # EVs don't reduce congestion
            "signal_opt_max_improvement": 0.20,  # 20% max from signals
            "metro_max_traffic_reduction": 0.25,  # 25% max from metro
            "metro_aqi_improvement": 0.15,  # 15% AQI improvement from metro
            "bus_rapid_transit_traffic": 0.12,  # 12% traffic improvement
            "cycling_infra_traffic": 0.05,  # 5% for cycling lanes
            
            # Construction/dust control
            "dust_control_aqi_improvement": 0.08,  # 8% from dust control
            "tree_planting_aqi_improvement": 0.03,  # 3% per 10% green cover increase
            
            # Economic multipliers
            "aqi_healthcare_cost_per_point": 2.5,  # Crore per AQI point per year
            "congestion_cost_per_percent": 10,  # Crore per 1% congestion
            "productivity_loss_per_minute": 1.2,  # Crore per minute avg commute increase
        }
        
        # Query categories for routing
        self.query_categories = {
            "ev_adoption": ["ev", "electric vehicle", "electric car", "ev adoption", "ev share"],
            "traffic": ["traffic", "congestion", "commute", "travel time", "road", "highway"],
            "air_quality": ["aqi", "air quality", "pollution", "pm2.5", "pm10", "smog", "air"],
            "metro": ["metro", "subway", "rail", "train", "public transport"],
            "infrastructure": ["road", "flyover", "bridge", "underpass", "signal", "intersection"],
            "policy": ["policy", "ban", "rule", "regulation", "government", "authority"],
            "comparison": ["compare", "vs", "versus", "better", "worse", "different"],
            "hypothetical": ["what if", "imagine", "suppose", "hypothetical", "scenario"],
        }
    
    def _load_data(self):
        """Load historical Noida data."""
        try:
            traffic_path = Path("data/noida_tomtom_daily.csv")
            if traffic_path.exists():
                self.traffic_data = pd.read_csv(traffic_path)
                
            aqi_path = Path("data/noida_aqi_2024.xlsx")
            if aqi_path.exists():
                self.aqi_data = pd.read_excel(aqi_path)
        except Exception as e:
            print(f"[MasterBrain] Data load warning: {e}")
    
    def _calculate_baselines(self) -> Dict[str, float]:
        """Calculate baselines from real data."""
        baselines = {
            "aqi": 201.0,  # Noida yearly average
            "speed_kmh": 27.6,  # Average speed
            "congestion_index": 0.65,  # 0-1 scale
        }
        
        if self.aqi_data is not None and 'AQI' in self.aqi_data.columns:
            baselines["aqi"] = float(self.aqi_data['AQI'].mean())
            
        if self.traffic_data is not None and 'avg_speed' in self.traffic_data.columns:
            baselines["speed_kmh"] = float(self.traffic_data['avg_speed'].mean())
            
        return baselines
    
    def _categorize_query(self, prompt: str) -> List[str]:
        """Identify what categories this query belongs to."""
        prompt_lower = prompt.lower()
        categories = []
        
        for category, keywords in self.query_categories.items():
            if any(kw in prompt_lower for kw in keywords):
                categories.append(category)
        
        if not categories:
            categories = ["general"]
            
        return categories
    
    async def research_topic(self, topic: str, context: str = "") -> Dict[str, Any]:
        """
        Use Gemini to research a topic with its knowledge.
        This is where the AI actually THINKS and REASONS.
        """
        
        if not self.model:
            return {"research": "Research unavailable", "confidence": 0.3}
        
        research_prompt = f"""You are an expert urban planner and researcher. Research this topic thoroughly.

TOPIC: {topic}

CONTEXT: {context if context else "Urban planning and mobility in Indian cities, specifically Noida."}

Provide a well-researched response as JSON:
{{
    "key_facts": [
        {{"fact": "specific fact with numbers if available", "source_type": "research/statistics/case_study", "confidence": 0.7-1.0}}
    ],
    "relevant_data": {{
        "numbers": {{"metric_name": value}},
        "comparisons": ["comparison to other cities/scenarios"],
        "trends": ["observed trends"]
    }},
    "expert_analysis": "Your expert analysis synthesizing the research",
    "caveats": ["important limitations or assumptions"],
    "confidence_level": "high/medium/low based on data availability"
}}

Be specific with numbers. Reference real-world examples (Delhi, Mumbai, Singapore, London, Beijing for air quality comparisons). For Indian context, use INR and crore for money."""

        try:
            response = self.model.generate_content(research_prompt)
            text = response.text
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            return json.loads(text.strip())
            
        except Exception as e:
            return {
                "key_facts": [{"fact": f"Research on {topic}", "source_type": "analysis", "confidence": 0.5}],
                "expert_analysis": f"Analysis of {topic} based on general urban planning principles.",
                "confidence_level": "medium"
            }
    
    async def brainstorm_hypothetical(self, scenario: str, baselines: Dict) -> Dict[str, Any]:
        """
        Handle hypothetical scenarios by combining physics + creativity.
        "What if Noida bans all petrol vehicles?" â†’ Physics + real-world examples
        """
        
        if not self.model:
            return {"scenario_analysis": "Analysis unavailable", "confidence": 0.3}
        
        hypothetical_prompt = f"""You are a creative urban planning analyst. Analyze this hypothetical scenario for Noida, India.

SCENARIO: "{scenario}"

CURRENT NOIDA BASELINES:
- Average AQI: {baselines.get('aqi', 201)}
- Average Traffic Speed: {baselines.get('speed_kmh', 27.6)} km/h
- Congestion Index: {baselines.get('congestion_index', 0.65)} (0-1 scale)

Provide a thorough hypothetical analysis as JSON:
{{
    "scenario_understanding": "What exactly is being proposed",
    "immediate_effects": [
        {{"effect": "effect description", "magnitude": "high/medium/low", "timeline": "immediate/weeks/months/years"}}
    ],
    "ripple_effects": [
        {{"effect": "secondary effect", "caused_by": "which immediate effect causes this"}}
    ],
    "projected_metrics": {{
        "aqi_change_percent": -X to +X (negative = improvement),
        "traffic_change_percent": -X to +X (negative = less congestion),
        "economic_impact_crore": +/- X
    }},
    "real_world_parallels": [
        {{"city": "city name", "similar_policy": "what they did", "outcome": "what happened"}}
    ],
    "feasibility": {{
        "technical": "high/medium/low",
        "political": "high/medium/low", 
        "economic": "high/medium/low"
    }},
    "recommendations": ["how to implement or modify the scenario"]
}}

Be creative but grounded. Reference real cities that tried similar things (Singapore congestion pricing, London ULEZ, Delhi odd-even, Paris car-free days, etc.)."""

        try:
            response = self.model.generate_content(hypothetical_prompt)
            text = response.text
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            return json.loads(text.strip())
            
        except Exception as e:
            return {
                "scenario_understanding": scenario,
                "projected_metrics": {"aqi_change_percent": 0, "traffic_change_percent": 0},
                "confidence_level": "low"
            }
    
    async def understand_query(self, prompt: str) -> Dict[str, Any]:
        """
        Step 1: Deep understanding of what the user wants.
        
        This determines the processing path:
        - CALCULATE: Physics-based (EV, signals, metro)
        - RESEARCH: Internet lookup (policy, comparisons)
        - HYPOTHETICAL: Creative analysis (what-if scenarios)
        - GENERAL: Direct Gemini response
        """
        
        categories = self._categorize_query(prompt)
        
        if not self.model:
            return self._fallback_understand(prompt, categories)
        
        understanding_prompt = f"""Analyze this urban planning query for Noida, India. Be very thorough.

Query: "{prompt}"

Determine:
1. What information the user needs
2. What data points would help answer this
3. Whether this needs calculation, research, or creative analysis

Respond as JSON:
{{
    "intent": "clear statement of what user wants to know",
    "query_type": "calculable" | "researchable" | "hypothetical" | "general",
    "requires_physics": true/false (if specific numbers like EV%, metro ridership can be calculated),
    "requires_research": true/false (if we need to look up real-world data or examples),
    "requires_creativity": true/false (if this is a what-if scenario),
    
    "extracted_parameters": {{
        "ev_adoption_percent": number or null,
        "metro_ridership_percent": number or null,
        "signal_optimization_percent": number or null,
        "dust_control_percent": number or null,
        "tree_cover_increase_percent": number or null,
        "other_interventions": ["list of other interventions mentioned"]
    }},
    
    "intervention_type": "ev_adoption" | "metro" | "signal_optimization" | "bus_lane" | "cycling" | "dust_control" | "green_cover" | "policy" | "multiple" | "general",
    "time_horizon": "immediate" | "short_term" | "long_term",
    "specific_location": "sector or area" or null,
    "metrics_requested": ["aqi", "traffic", "economic", "health", "emissions", "all"],
    "comparison_needed": true/false,
    "comparison_targets": ["what to compare against if comparison_needed"]
}}

Extract ALL numbers mentioned. If user says "50% EV" then ev_adoption_percent = 50.
If user asks about multiple things, capture all of them."""

        try:
            response = self.model.generate_content(understanding_prompt)
            text = response.text
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            understanding = json.loads(text.strip())
            understanding["raw_prompt"] = prompt
            understanding["categories"] = categories
            return understanding
            
        except Exception as e:
            return self._fallback_understand(prompt, categories)
    
    def _fallback_understand(self, prompt: str, categories: List[str] = None) -> Dict[str, Any]:
        """Regex-based fallback for understanding."""
        
        prompt_lower = prompt.lower()
        
        # Extract percentages for various interventions
        ev_match = re.search(r'(\d+)\s*%\s*(?:ev|electric)', prompt_lower)
        metro_match = re.search(r'(\d+)\s*%\s*(?:metro|public transport)', prompt_lower)
        signal_match = re.search(r'(\d+)\s*%\s*(?:signal|traffic light)', prompt_lower)
        
        ev_pct = float(ev_match.group(1)) if ev_match else None
        metro_pct = float(metro_match.group(1)) if metro_match else None
        signal_pct = float(signal_match.group(1)) if signal_match else None
        
        # If no explicit match but EV context exists
        if ev_pct is None and ('ev' in prompt_lower or 'electric' in prompt_lower):
            pct_match = re.search(r'(\d+)\s*%', prompt_lower)
            if pct_match:
                ev_pct = float(pct_match.group(1))
        
        # Determine query type
        is_hypothetical = any(kw in prompt_lower for kw in ['what if', 'imagine', 'suppose', 'hypothetical'])
        has_numbers = bool(ev_pct or metro_pct or signal_pct)
        
        if is_hypothetical:
            query_type = "hypothetical"
        elif has_numbers:
            query_type = "calculable"
        else:
            query_type = "general"
        
        return {
            "intent": f"Analyze: {prompt[:100]}",
            "query_type": query_type,
            "requires_physics": has_numbers,
            "requires_research": not has_numbers,
            "requires_creativity": is_hypothetical,
            "extracted_parameters": {
                "ev_adoption_percent": ev_pct,
                "metro_ridership_percent": metro_pct,
                "signal_optimization_percent": signal_pct,
            },
            "intervention_type": "ev_adoption" if ev_pct else ("metro" if metro_pct else "general"),
            "time_horizon": "short_term",
            "specific_location": None,
            "metrics_requested": ["aqi", "traffic", "economic"],
            "raw_prompt": prompt,
            "categories": categories or ["general"]
        }
    
    def calculate_ev_impact(self, ev_percent: float) -> Dict[str, Any]:
        """
        Calculate EV impact using PHYSICS.
        This is DETERMINISTIC - same input = same output.
        Cannot give wrong results like "AQI increases with EV".
        """
        
        if ev_percent is None or ev_percent <= 0:
            return {
                "ev_percent": 0,
                "aqi_change_percent": 0,
                "aqi_baseline": self.baselines["aqi"],
                "aqi_projected": self.baselines["aqi"],
                "traffic_change_percent": 0,
                "calculation_type": "physics",
                "explanation": "No EV adoption specified."
            }
        
        # Clamp to valid range
        ev_percent = min(max(ev_percent, 0), 100)
        
        # Calculate AQI reduction (ALWAYS negative = improvement)
        aqi_reduction = min(
            ev_percent * self.physics["ev_aqi_reduction_per_percent"],
            self.physics["max_ev_aqi_reduction"]
        )
        
        baseline_aqi = self.baselines["aqi"]
        projected_aqi = baseline_aqi * (1 - aqi_reduction)
        
        # Traffic doesn't change much with EVs
        traffic_change = 0.0
        
        # Economic impact
        aqi_improvement_points = baseline_aqi - projected_aqi
        healthcare_savings = aqi_improvement_points * self.physics["aqi_healthcare_cost_per_point"]
        
        return {
            "intervention": "ev_adoption",
            "ev_percent": ev_percent,
            "aqi_baseline": round(baseline_aqi, 0),
            "aqi_projected": round(projected_aqi, 0),
            "aqi_change_percent": round(-aqi_reduction * 100, 1),
            "aqi_improvement_points": round(aqi_improvement_points, 0),
            "traffic_change_percent": traffic_change,
            "speed_baseline": self.baselines["speed_kmh"],
            "speed_projected": self.baselines["speed_kmh"],  # No change for EV
            "healthcare_savings_crore": round(healthcare_savings, 1),
            "calculation_type": "physics",
            "explanation": f"At {ev_percent}% EV adoption, vehicular emissions reduce by ~{ev_percent*0.7:.0f}%. "
                          f"Since vehicles contribute ~35% of Noida's PM2.5, total AQI improves by ~{aqi_reduction*100:.1f}%. "
                          f"This means AQI drops from {baseline_aqi:.0f} to {projected_aqi:.0f}."
        }
    
    def calculate_multi_intervention(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate combined impact of multiple interventions."""
        
        baseline_aqi = self.baselines["aqi"]
        baseline_speed = self.baselines["speed_kmh"]
        
        total_aqi_reduction = 0
        total_traffic_improvement = 0
        explanations = []
        
        # EV adoption
        ev_pct = params.get("ev_adoption_percent")
        if ev_pct and ev_pct > 0:
            ev_impact = min(ev_pct * self.physics["ev_aqi_reduction_per_percent"], 
                          self.physics["max_ev_aqi_reduction"])
            total_aqi_reduction += ev_impact
            explanations.append(f"EV ({ev_pct}%): AQI -{ev_impact*100:.1f}%")
        
        # Metro/public transport
        metro_pct = params.get("metro_ridership_percent")
        if metro_pct and metro_pct > 0:
            metro_traffic = min(metro_pct/100 * self.physics["metro_max_traffic_reduction"], 
                               self.physics["metro_max_traffic_reduction"])
            metro_aqi = min(metro_pct/100 * self.physics["metro_aqi_improvement"],
                          self.physics["metro_aqi_improvement"])
            total_traffic_improvement += metro_traffic
            total_aqi_reduction += metro_aqi
            explanations.append(f"Metro ({metro_pct}%): Traffic +{metro_traffic*100:.1f}%, AQI -{metro_aqi*100:.1f}%")
        
        # Signal optimization
        signal_pct = params.get("signal_optimization_percent")
        if signal_pct and signal_pct > 0:
            signal_traffic = min(signal_pct/100 * self.physics["signal_opt_max_improvement"],
                                self.physics["signal_opt_max_improvement"])
            signal_aqi = signal_traffic * 0.2  # Less idling
            total_traffic_improvement += signal_traffic
            total_aqi_reduction += signal_aqi
            explanations.append(f"Signals ({signal_pct}%): Traffic +{signal_traffic*100:.1f}%")
        
        # Dust control
        dust_pct = params.get("dust_control_percent")
        if dust_pct and dust_pct > 0:
            dust_aqi = min(dust_pct/100 * self.physics["dust_control_aqi_improvement"],
                         self.physics["dust_control_aqi_improvement"])
            total_aqi_reduction += dust_aqi
            explanations.append(f"Dust control ({dust_pct}%): AQI -{dust_aqi*100:.1f}%")
        
        # Green cover
        green_pct = params.get("tree_cover_increase_percent")
        if green_pct and green_pct > 0:
            green_aqi = green_pct/10 * self.physics["tree_planting_aqi_improvement"]
            total_aqi_reduction += green_aqi
            explanations.append(f"Green cover (+{green_pct}%): AQI -{green_aqi*100:.1f}%")
        
        # Calculate final values
        projected_aqi = baseline_aqi * (1 - total_aqi_reduction)
        projected_speed = baseline_speed * (1 + total_traffic_improvement)
        
        # Economic savings
        aqi_points_saved = baseline_aqi - projected_aqi
        healthcare_savings = aqi_points_saved * self.physics["aqi_healthcare_cost_per_point"]
        congestion_savings = total_traffic_improvement * 100 * self.physics["congestion_cost_per_percent"]
        
        return {
            "intervention": "multiple",
            "aqi_baseline": round(baseline_aqi, 0),
            "aqi_projected": round(max(projected_aqi, 50), 0),  # AQI can't go below 50 reasonably
            "aqi_change_percent": round(-total_aqi_reduction * 100, 1),
            "speed_baseline": round(baseline_speed, 1),
            "speed_projected": round(min(projected_speed, 50), 1),  # Max 50 km/h in urban
            "traffic_change_percent": round(total_traffic_improvement * 100, 1),
            "healthcare_savings_crore": round(healthcare_savings, 1),
            "congestion_savings_crore": round(congestion_savings, 1),
            "total_economic_benefit_crore": round(healthcare_savings + congestion_savings, 1),
            "calculation_type": "physics",
            "breakdown": explanations,
            "explanation": " | ".join(explanations) if explanations else "No calculable interventions specified."
        }
        
    def calculate_general_impact(self, intervention_type: str, intensity: float = 0.5) -> Dict[str, Any]:
        """Calculate impact for specific non-EV interventions."""
        
        baseline_aqi = self.baselines["aqi"]
        baseline_speed = self.baselines["speed_kmh"]
        
        aqi_improvement = 0
        traffic_improvement = 0
        explanation = ""
        
        if intervention_type == "metro":
            traffic_improvement = intensity * self.physics["metro_max_traffic_reduction"]
            aqi_improvement = intensity * self.physics["metro_aqi_improvement"]
            explanation = f"Metro expansion at {intensity*100:.0f}% capacity reduces road traffic by {traffic_improvement*100:.1f}% and improves AQI by {aqi_improvement*100:.1f}%"
            
        elif intervention_type == "signal_optimization":
            traffic_improvement = intensity * self.physics["signal_opt_max_improvement"]
            aqi_improvement = traffic_improvement * 0.2
            explanation = f"Signal optimization at {intensity*100:.0f}% coverage improves traffic flow by {traffic_improvement*100:.1f}%"
            
        elif intervention_type == "bus_lane":
            traffic_improvement = intensity * self.physics["bus_rapid_transit_traffic"]
            aqi_improvement = intensity * 0.05
            explanation = f"Bus rapid transit at {intensity*100:.0f}% coverage improves traffic by {traffic_improvement*100:.1f}%"
            
        elif intervention_type == "cycling":
            traffic_improvement = intensity * self.physics["cycling_infra_traffic"]
            aqi_improvement = intensity * 0.02
            explanation = f"Cycling infrastructure at {intensity*100:.0f}% coverage has modest traffic impact"
            
        elif intervention_type == "dust_control":
            aqi_improvement = intensity * self.physics["dust_control_aqi_improvement"]
            explanation = f"Dust control at {intensity*100:.0f}% effectiveness improves AQI by {aqi_improvement*100:.1f}%"
            
        elif intervention_type == "green_cover":
            aqi_improvement = intensity * self.physics["tree_planting_aqi_improvement"]
            explanation = f"Green cover increase improves AQI by {aqi_improvement*100:.1f}%"
        
        projected_aqi = baseline_aqi * (1 - aqi_improvement)
        projected_speed = baseline_speed * (1 + traffic_improvement)
        
        return {
            "intervention": intervention_type,
            "intensity": intensity,
            "aqi_baseline": round(baseline_aqi, 0),
            "aqi_projected": round(projected_aqi, 0),
            "aqi_change_percent": round(-aqi_improvement * 100, 1),
            "speed_baseline": round(baseline_speed, 1),
            "speed_projected": round(projected_speed, 1),
            "traffic_change_percent": round(traffic_improvement * 100, 1),
            "calculation_type": "physics",
            "explanation": explanation
        }
    
    async def answer_general_question(self, prompt: str, context: Dict = None) -> Dict[str, Any]:
        """
        Handle general questions that don't need physics calculations.
        Uses Gemini to provide intelligent, researched answers.
        """
        
        if not self.model:
            return None
        
        noida_context = f"""
NOIDA CURRENT DATA (2024):
- Average AQI: {self.baselines.get('aqi', 201):.0f} (Poor to Very Poor category)
- Average Traffic Speed: {self.baselines.get('speed_kmh', 27.6):.1f} km/h
- Congestion Index: {self.baselines.get('congestion_index', 0.65):.2f} (moderate-high)
- Key pollution sources: Vehicles (~35%), Construction dust (~20%), Industry (~15%), Others

COMPARISON DATA (approximate):
- Delhi AQI: 250-300 average (Severe)
- Gurugram AQI: 180-220 average (Poor)
- Bangalore AQI: 80-120 average (Moderate)
- Mumbai AQI: 100-150 average (Moderate-Poor)
"""
        
        general_prompt = f"""You are an expert urban mobility and environmental analyst. Answer this question thoroughly.

QUESTION: {prompt}

{noida_context}

Provide a comprehensive answer as JSON:
{{
    "executive_summary": "Clear, direct answer in 2-3 sentences with specific data",
    "key_findings": [
        {{"finding": "specific finding with numbers", "confidence": 0.7-1.0, "source": "data/analysis/research"}}
    ],
    "detailed_analysis": {{
        "primary_answer": "2-3 paragraphs fully answering the question",
        "supporting_evidence": "Data and sources backing this up",
        "caveats": "Limitations to keep in mind"
    }},
    "metrics_summary": {{
        "aqi": {{"current": {self.baselines.get('aqi', 201)}, "context": "explanation"}},
        "traffic": {{"current": {self.baselines.get('speed_kmh', 27.6)}, "context": "explanation"}}
    }},
    "real_world_context": {{
        "similar_cities": ["relevant comparison cities"],
        "lessons": ["what Noida can learn"]
    }},
    "recommendations": [
        {{"recommendation": "actionable step", "priority": "high/medium/low", "timeline": "immediate/short_term/long_term"}}
    ],
    "transparency": {{
        "calculation_method": "ai-reasoned",
        "confidence_level": "high/medium/low",
        "data_sources": ["sources used"]
    }}
}}

Be conversational and helpful. Use real data and specific numbers."""

        try:
            response = self.model.generate_content(general_prompt)
            text = response.text
            
            # Try to extract JSON from various formats
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            # Clean up common issues
            text = text.strip()
            
            try:
                return json.loads(text)
            except json.JSONDecodeError:
                # Try to find JSON object in the text
                import re
                json_match = re.search(r'\{[\s\S]*\}', text)
                if json_match:
                    return json.loads(json_match.group())
                return None
            
        except Exception as e:
            print(f"[MasterBrain] General question error: {e}")
            return None
    
    async def generate_comprehensive_response(self, understanding: Dict, calculations: Dict, 
                                               research: Dict = None, hypothetical: Dict = None) -> Dict[str, Any]:
        """
        Generate a comprehensive, ChatGPT-like response.
        Combines calculations, research, and creative analysis.
        """
        
        if not self.model:
            return self._fallback_response(understanding, calculations)
        
        # Build context from all available data
        context_parts = []
        
        if calculations:
            context_parts.append(f"CALCULATED RESULTS (physics-based, verified):\n{json.dumps(calculations, indent=2)}")
        
        if research:
            context_parts.append(f"RESEARCH FINDINGS:\n{json.dumps(research, indent=2)}")
        
        if hypothetical:
            context_parts.append(f"HYPOTHETICAL ANALYSIS:\n{json.dumps(hypothetical, indent=2)}")
        
        combined_context = "\n\n".join(context_parts)
        
        response_prompt = f"""You are an expert urban mobility analyst for Noida, India. Think like a senior consultant presenting to city officials.

USER QUERY: "{understanding.get('raw_prompt', '')}"

AVAILABLE DATA AND ANALYSIS:
{combined_context}

Generate a comprehensive, conversational response as JSON:
{{
    "executive_summary": "2-3 sentences directly answering the user. Be conversational and confident. Use specific numbers.",
    
    "key_findings": [
        {{"finding": "specific finding with exact numbers", "confidence": 0.7-1.0, "source": "calculation/research/analysis"}},
        // 3-5 key findings
    ],
    
    "detailed_analysis": {{
        "primary_answer": "Detailed answer to what user asked (2-3 paragraphs)",
        "supporting_evidence": "What data backs this up",
        "caveats": "Important limitations or assumptions"
    }},
    
    "metrics_summary": {{
        "aqi": {{"current": X, "projected": Y, "change": "Z%", "interpretation": "text"}},
        "traffic": {{"current": X, "projected": Y, "change": "Z%", "interpretation": "text"}},
        "economic": {{"benefit_crore": X, "interpretation": "text"}}
    }},
    
    "real_world_context": {{
        "similar_cities": ["cities that did similar things"],
        "lessons": ["what we can learn from them"]
    }},
    
    "recommendations": [
        {{"recommendation": "actionable step", "priority": "high/medium/low", "timeline": "immediate/short_term/long_term"}}
    ],
    
    "transparency": {{
        "calculation_method": "physics-based/ai-reasoned/hybrid",
        "confidence_level": "high/medium/low",
        "data_sources": ["list sources used"]
    }}
}}

IMPORTANT GUIDELINES:
1. Be conversational, not robotic. Write like you're explaining to a smart colleague.
2. Use the EXACT numbers from calculations - don't make up different numbers.
3. If AQI goes from 201 to 176, say that explicitly - "AQI will improve from 201 to 176".
4. For Indian context, use â‚¹, crore, lakh appropriately.
5. Reference real cities for credibility (Singapore, London, Delhi, Bangalore).
6. Acknowledge what's calculated vs what's estimated."""

        try:
            response = self.model.generate_content(response_prompt)
            text = response.text
            
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            return json.loads(text.strip())
            
        except Exception as e:
            return self._fallback_response(understanding, calculations)
    
    def _fallback_response(self, understanding: Dict, calculations: Dict) -> Dict[str, Any]:
        """Generate response without Gemini - use available data intelligently."""
        
        aqi_baseline = calculations.get("aqi_baseline", 201)
        aqi_projected = calculations.get("aqi_projected", 201)
        aqi_change = calculations.get("aqi_change_percent", 0)
        intervention = calculations.get("intervention", "general")
        raw_prompt = understanding.get("raw_prompt", "")
        
        # Generate a contextual summary based on the query
        if aqi_change != 0:
            summary = f"Based on our analysis for Noida, the proposed intervention would change AQI from {aqi_baseline:.0f} to {aqi_projected:.0f} ({aqi_change:+.1f}%). {calculations.get('explanation', '')}"
        else:
            # For general queries, provide helpful context
            summary = f"Noida's current average AQI is {aqi_baseline:.0f} (categorized as 'Poor' to 'Very Poor'). For comparison, Delhi's AQI averages around 250-300. {raw_prompt}"
        
        return {
            "executive_summary": summary,
            "key_findings": [
                {"finding": f"Noida's average AQI is {aqi_baseline:.0f}", "confidence": 0.95, "source": "sensor_data"},
                {"finding": f"AQI changes to {aqi_projected:.0f} ({abs(aqi_change):.1f}% {'improvement' if aqi_change < 0 else 'change'})" if aqi_change != 0 else "Current baselines shown - specify an intervention for projections", "confidence": 0.90, "source": "calculation"},
                {"finding": f"Traffic speed impact: {calculations.get('traffic_change_percent', 0):+.1f}%", "confidence": 0.85, "source": "calculation"},
            ],
            "detailed_analysis": {
                "primary_answer": calculations.get("explanation", f"Analysis based on Noida's actual traffic and air quality data from 2024. Current average AQI is {aqi_baseline:.0f}."),
                "supporting_evidence": "Based on Noida TomTom traffic data (365 days) and AQI sensor data (366 days)",
                "caveats": "Results assume full implementation and typical weather conditions"
            },
            "metrics_summary": {
                "aqi": {"current": aqi_baseline, "projected": aqi_projected, "change": f"{aqi_change:+.1f}%"},
                "traffic": {"change": f"{calculations.get('traffic_change_percent', 0):+.1f}%"}
            },
            "real_world_context": {
                "similar_cities": ["Delhi", "Gurugram", "Greater Noida"],
                "lessons": ["Targeted interventions like metro, EV adoption, and dust control can significantly improve AQI"]
            },
            "recommendations": [
                {"recommendation": "Try asking about specific interventions like '50% EV adoption' or 'metro expansion'", "priority": "high", "timeline": "immediate"},
                {"recommendation": "Compare with Delhi to understand regional air quality patterns", "priority": "medium", "timeline": "short_term"}
            ],
            "transparency": {
                "calculation_method": "physics-based" if calculations.get("calculation_type") == "physics" else "baseline",
                "confidence_level": "high" if aqi_change != 0 else "medium",
                "data_sources": ["Noida TomTom traffic data 2024", "Noida AQI sensors 2024"]
            }
        }
    
    async def process(self, prompt: str) -> Dict[str, Any]:
        """
        Main entry point - handles ANY query intelligently.
        
        Flow:
        1. UNDERSTAND - What does the user want? (Gemini)
        2. ROUTE - Is this calculable, researchable, or hypothetical?
        3. PROCESS - Use appropriate method
        4. RESPOND - Generate comprehensive response
        """
        
        logs = []
        started_at = datetime.now()
        logs.append(f"ðŸ§  Master Brain activated at {started_at.strftime('%H:%M:%S')}")
        
        # Step 1: Deep understanding
        logs.append("ðŸ“Š Step 1: Understanding your query...")
        understanding = await self.understand_query(prompt)
        logs.append(f"âœ“ Understood: {understanding.get('intent', 'Processing...')[:80]}")
        
        query_type = understanding.get("query_type", "general")
        logs.append(f"âœ“ Query type: {query_type}")
        
        # Step 2: Process based on query type
        calculations = None
        research = None
        hypothetical = None
        
        params = understanding.get("extracted_parameters", {})
        ev_pct = params.get("ev_adoption_percent")
        
        if ev_pct:
            logs.append(f"âœ“ Detected EV adoption: {ev_pct}%")
        
        # Physics-based calculations (when we have specific numbers)
        if understanding.get("requires_physics") or ev_pct:
            logs.append("ðŸ”¬ Step 2a: Calculating impacts (physics-based)...")
            
            if ev_pct and ev_pct > 0:
                calculations = self.calculate_ev_impact(ev_pct)
            elif any(params.get(k) for k in ["metro_ridership_percent", "signal_optimization_percent", 
                                              "dust_control_percent", "tree_cover_increase_percent"]):
                calculations = self.calculate_multi_intervention(params)
            else:
                intervention = understanding.get("intervention_type", "general")
                calculations = self.calculate_general_impact(intervention)
            
            logs.append(f"âœ“ AQI: {calculations.get('aqi_baseline', 0):.0f} â†’ {calculations.get('aqi_projected', 0):.0f}")
        
        # Research (when we need real-world data or comparisons)
        if understanding.get("requires_research") or query_type == "researchable":
            logs.append("ðŸ” Step 2b: Researching topic...")
            research = await self.research_topic(prompt, f"Categories: {understanding.get('categories', [])}")
            logs.append("âœ“ Research complete")
        
        # Hypothetical analysis (for what-if scenarios)
        if understanding.get("requires_creativity") or query_type == "hypothetical":
            logs.append("ðŸ’­ Step 2c: Analyzing hypothetical scenario...")
            hypothetical = await self.brainstorm_hypothetical(prompt, self.baselines)
            logs.append("âœ“ Hypothetical analysis complete")
            
            # Use hypothetical metrics if no physics calculations
            if not calculations and hypothetical:
                metrics = hypothetical.get("projected_metrics", {})
                aqi_change = metrics.get("aqi_change_percent", 0)
                traffic_change = metrics.get("traffic_change_percent", 0)
                
                # If Gemini gave us real metrics, use them
                if aqi_change != 0 or traffic_change != 0:
                    projected_aqi = self.baselines["aqi"] * (1 + aqi_change/100)
                    projected_speed = self.baselines["speed_kmh"] * (1 + traffic_change/100)
                else:
                    # Estimate based on scenario type
                    scenario_lower = prompt.lower()
                    if "ban" in scenario_lower or "car-free" in scenario_lower:
                        # Car bans typically reduce AQI by 10-20% on affected days
                        aqi_change = -15
                        traffic_change = 30  # Traffic improves without cars
                    elif "metro" in scenario_lower:
                        aqi_change = -10
                        traffic_change = 20
                    else:
                        aqi_change = -5
                        traffic_change = 5
                    
                    projected_aqi = self.baselines["aqi"] * (1 + aqi_change/100)
                    projected_speed = self.baselines["speed_kmh"] * (1 + traffic_change/100)
                
                calculations = {
                    "intervention": "hypothetical",
                    "aqi_baseline": round(self.baselines["aqi"], 0),
                    "aqi_projected": round(projected_aqi, 0),
                    "aqi_change_percent": aqi_change,
                    "speed_baseline": round(self.baselines["speed_kmh"], 1),
                    "speed_projected": round(projected_speed, 1),
                    "traffic_change_percent": traffic_change,
                    "calculation_type": "ai-reasoned",
                    "explanation": hypothetical.get("scenario_understanding", f"Hypothetical analysis: {prompt[:100]}")
                }
                logs.append(f"âœ“ Hypothetical AQI: {calculations['aqi_baseline']:.0f} â†’ {calculations['aqi_projected']:.0f}")
        
        # Ensure we have some calculations
        if not calculations:
            calculations = {
                "intervention": "general",
                "aqi_baseline": self.baselines["aqi"],
                "aqi_projected": self.baselines["aqi"],
                "aqi_change_percent": 0,
                "speed_baseline": self.baselines["speed_kmh"],
                "speed_projected": self.baselines["speed_kmh"],
                "traffic_change_percent": 0,
                "calculation_type": "baseline",
                "explanation": "No specific intervention detected - showing current baselines."
            }
        
        # Step 3: Generate comprehensive response
        logs.append("ðŸ“ Step 3: Generating comprehensive response...")
        
        # For general queries without calculations, try direct Gemini response
        if query_type == "general" and calculations.get("calculation_type") == "baseline":
            logs.append("ðŸ’¬ Using AI reasoning for general query...")
            general_response = await self.answer_general_question(prompt, {"baselines": self.baselines})
            if general_response:
                response = general_response
                logs.append("âœ“ AI response generated")
            else:
                response = await self.generate_comprehensive_response(understanding, calculations, research, hypothetical)
        else:
            response = await self.generate_comprehensive_response(understanding, calculations, research, hypothetical)
        
        logs.append("âœ“ Response ready")
        
        elapsed = (datetime.now() - started_at).total_seconds()
        logs.append(f"â± Completed in {elapsed:.1f}s")
        
        return {
            "understanding": understanding,
            "calculations": calculations,
            "research": research,
            "hypothetical": hypothetical,
            "response": response,
            "logs": logs,
            "meta": {
                "query_type": query_type,
                "calculation_type": calculations.get("calculation_type", "unknown"),
                "elapsed_seconds": elapsed
            }
        }


# Global instance
_master_brain = None

def get_master_brain() -> MasterBrain:
    global _master_brain
    if _master_brain is None:
        _master_brain = MasterBrain()
    return _master_brain


async def analyze(prompt: str) -> Dict[str, Any]:
    """Main entry point."""
    brain = get_master_brain()
    return await brain.process(prompt)
